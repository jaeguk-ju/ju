{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOnSu11xr5HzU0nZ3mNOJJf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaeguk-ju/ju/blob/master/horse_and_human_B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DH0TwwecnDk2",
        "outputId": "fa91996b-1778-4c5f-8dff-cd3a25bd8c9c"
      },
      "source": [
        "# Question\r\n",
        "#\r\n",
        "# This task requires you to create a classifier for horses or humans using\r\n",
        "# the provided data. Please make sure your final layer is a 1 neuron, activated by sigmoid as shown.\r\n",
        "# Please note that the test will use images that are 300x300 with 3 bytes color depth so be sure to design your neural network accordingly\r\n",
        "\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "import urllib\r\n",
        "import zipfile\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\r\n",
        "tf.random.set_seed(1234)\r\n",
        "\r\n",
        "def solution_model():\r\n",
        "    _TRAIN_URL = \"https://storage.googleapis.com/download.tensorflow.org/data/horse-or-human.zip\"\r\n",
        "    _TEST_URL = \"https://storage.googleapis.com/download.tensorflow.org/data/validation-horse-or-human.zip\"\r\n",
        "    urllib.request.urlretrieve(_TRAIN_URL, 'horse-or-human.zip')\r\n",
        "    local_zip = 'horse-or-human.zip'\r\n",
        "    zip_ref = zipfile.ZipFile(local_zip, 'r')\r\n",
        "    zip_ref.extractall('./tmp/horse-or-human/')\r\n",
        "    zip_ref.close()\r\n",
        "    urllib.request.urlretrieve(_TEST_URL, 'validation-horse-or-human.zip')\r\n",
        "    local_zip = 'validation-horse-or-human.zip'\r\n",
        "    zip_ref = zipfile.ZipFile(local_zip, 'r')\r\n",
        "    zip_ref.extractall('./tmp/validation-horse-or-human/')\r\n",
        "    zip_ref.close()\r\n",
        "\r\n",
        "    train_datagen = ImageDataGenerator(\r\n",
        "        #Your code here. Should at least have a rescale. Other parameters can help with overfitting.)\r\n",
        "        rescale = 1/255., \r\n",
        "        shear_range = 0.2,\r\n",
        "        zoom_range =0.2,\r\n",
        "        horizontal_flip=True)\r\n",
        "   \r\n",
        "    \r\n",
        "    # 데이터소스의 위치, 이미지크기, 배치사이즈, 라벨\r\n",
        "    train_generator = train_datagen.flow_from_directory(\r\n",
        "        #Your Code Here\r\n",
        "        './tmp/horse-or-human/',\r\n",
        "        target_size=(300,300),\r\n",
        "        batch_size=32, \r\n",
        "        class_mode = 'binary'\r\n",
        "        )\r\n",
        "\r\n",
        "    \r\n",
        "    \r\n",
        "    validation_datagen = ImageDataGenerator(\r\n",
        "        #Your Code here\r\n",
        "        rescale= 1/255.\r\n",
        "    )\r\n",
        "    \r\n",
        "    validation_generator = validation_datagen.flow_from_directory(\r\n",
        "        #Your Code Here\r\n",
        "        './tmp/validation-horse-or-human/',\r\n",
        "        target_size=(300,300),\r\n",
        "        batch_size=32,\r\n",
        "        class_mode='binary'\r\n",
        "    )\r\n",
        "\r\n",
        "\r\n",
        "    model = tf.keras.models.Sequential([\r\n",
        "        # Note the input shape specified on your first layer must be (300,300,3)\r\n",
        "        # Your Code here\r\n",
        "        tf.keras.layers.Conv2D(32,(3,3), input_shape=(300,300,3), activation='relu'),\r\n",
        "        tf.keras.layers.MaxPool2D(2,2),\r\n",
        "        tf.keras.layers.Conv2D(64, (3,3),activation='relu'),\r\n",
        "        tf.keras.layers.MaxPool2D(2,2),\r\n",
        "        tf.keras.layers.Conv2D(128, (3,3),activation='relu'),\r\n",
        "        tf.keras.layers.MaxPool2D(2,2),\r\n",
        "        tf.keras.layers.Conv2D(128, (3,3),activation='relu'),\r\n",
        "        tf.keras.layers.MaxPool2D(2,2),\r\n",
        "        tf.keras.layers.Conv2D(256, (3,3),activation='relu'),\r\n",
        "        tf.keras.layers.MaxPool2D(2,2),\r\n",
        "        tf.keras.layers.Flatten() ,\r\n",
        "        tf.keras.layers.Dropout(0.5),\r\n",
        "        tf.keras.layers.Dense(512, activation='relu'),\r\n",
        "        tf.keras.layers.Dropout(0.5),    #hjkim\r\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\r\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\r\n",
        "        # This is the last layer. You should not change this code.\r\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\r\n",
        "    ])\r\n",
        "    # print(model.summary())\r\n",
        "\r\n",
        "\r\n",
        "    model.compile(#Your Code Here#\r\n",
        "        loss='binary_crossentropy', optimizer='adam', metrics=['acc']\r\n",
        "    )\r\n",
        "\r\n",
        "    checkpoint_path = 'my_checkpoint2.ckpt'\r\n",
        "    checkpoint = ModelCheckpoint(filepath=checkpoint_path, save_weights_only=True, save_best_only=True , monitor='val_loss', verbose=1)\r\n",
        "    model.fit(\r\n",
        "        #Your Code Here#\r\n",
        "        train_generator, validation_data=validation_generator, epochs=10, callbacks=[checkpoint])\r\n",
        "   \r\n",
        "    model.load_weights(checkpoint_path)\r\n",
        "    # NOTE: If training is taking a very long time, you should consider setting the batch size appropriately on the generator, and the steps per epoch in the model.fit#\r\n",
        "    return model\r\n",
        "\r\n",
        "\r\n",
        "# Note that you'll need to save your model as a .h5 like this\r\n",
        "# This .h5 will be uploaded to the testing infrastructure\r\n",
        "# and a score will be returned to you\r\n",
        "if __name__ == '__main__':\r\n",
        "    model = solution_model()\r\n",
        "    model.save(\"cat3_horses_or_humans(typeB)_model1.h5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "33/33 [==============================] - 23s 682ms/step - loss: 0.6659 - acc: 0.5549 - val_loss: 0.6454 - val_acc: 0.8789\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.64541, saving model to my_checkpoint2.ckpt\n",
            "Epoch 2/10\n",
            "33/33 [==============================] - 22s 676ms/step - loss: 0.3190 - acc: 0.8768 - val_loss: 2.4274 - val_acc: 0.7578\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.64541\n",
            "Epoch 3/10\n",
            "24/33 [====================>.........] - ETA: 5s - loss: 0.1809 - acc: 0.9384"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}